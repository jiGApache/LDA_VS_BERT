 —Using deep learning models to classify time series data generated from the Internet of Things devices requires large amount of labeled data. However, due to constrained resources available in IoT devices, it is often difficult to accommodate training using large data sets. This paper proposes and demonstrates Similarity Learning-based Few Shot Learning for ECG arrhythmia classification using Siamese Convolutional Neural Networks. Few shot learning resolves the data scarcity issue identifying novel classes from very few labeled examples. Few Shot Learning relies first on pretraining the model on related relatively large database, and then the learning is used for further adaptation towards few examples available per class.Our experiments evaluate the performance accuracy with respect to for ECG time series data classification. The accuracy with shot learning is which marginally improves with further increase in K. We also compare the performance of our method against other well-established similarity learning techniques such as Dynamic Time Warping , Euclidean Distance , and deep learning model Long Short Term Memory Fully Convolutional Network with the same amount of data and conclude that our method outperforms them for dataset size. For the accuracies obtained are and approximately for ED, DTW, LSTM-FCN, and SCNN, respectively. I. INTRODUCTION Timeseries are significant class of temporal data objects. It is generated effortlessly recording sequence of observations Examples of time series are the price of stocks, electrocardiogram , target star’s brightness, daily temperature, weekly sales totals, etc . Time series classification task is training classifier on dataset to map inputs into one of the existing classes. Here, is univariate or multivariate time series, and is the class label. ECG classification comes under Time series classification problem. Studies show that the number of mortalities will increase from million to million due to prevalence of cardiovascular diseases. ECG being noninvasive and painless is often used as step towards treating heart diseases. ECG classification is important as it provides valuable information about the functioning of the circulatory system. ECG is univariate time series that has been used as the input for our work and consists of five different classes. TSC tasks are different from traditional classification problems as the attributes have temporal ordering; however, various machine learning and deep learning-based techniques have been applied in the literature to address this problem. In authors have evaluated machine learning-based time series algorithms and concluded Dynamic Time Warping performs better after Collective of Transformation Ensembles ensembles. Similarly, presents study of different deep learning techniques and concludes Residual Network followed Fully Convolutional Network performs better among them. However, the performance for each of these techniques is constrained the amount of labeled data. With the current we need subject matter expert to label data, and then the supervised learning techniques are applied to it. Manual labelling may result in inexact and noisy labels. Also, the cost of labelling the data and the time required for big data labelling is very high and not scalable. Therefore, there is need for learning techniques that can do cost-effective data classification with few labelled data and have accuracy at par with the supervised learning techniques that use large labelled data sets. From our study, we infer that there are research gaps in the design and development of time series classification techniques with few labelled data. The explosive growth of the Internet of Things devices emphasizes the need to develop classification that can generalize well from few labelled data. IoT devices are generally resource-constrained and cannot store large data sets for training purposes. There are high costs associated with obtaining labelled data as well. Further, the properties of ECG data collected IoT devices also present specific challenges like Class imbalance problem due to rare occurrence of some ECG events Low sampling frequency, single ECG lead and unavoidable noisiness may cause low signal quality and Small labelled data set due to high cost of labelling, and non-scalability . In the current work, we try to address the first and third challenges applying Siamese Convolutional Neural Network for class imbalance problems and few-shot learning for unavailability of extensive labelled data. In this work, we specifically try to address the problem of ECG classification using few labelled examples and this approach is termed Few Shot Learning. FSL is Weak Supervised Learning technique with incomplete supervision where only small amount of samples have supervised information . FSL uses transfer learning approach that tries to solve the task of learning from few given examples, called the support set. Transfer learning is technique wherein knowledge gained in learning for one task is utilized for solving another task . In FSL, the model is pre-trained on different related large dataset and then uses the learning for new task with fewer labelled data samples per class. FSL techniques are efficient in bridging the gap between model generalization performance and data set size . Previous works have shown that transfer learning shows promising results for solving the TSC , , . It involves the idea of pre-training model on large data to prevent overfitting, then tuning the pre-trained model to classify new data. In authors selected UCR datasets to perform pre-training and tested on another data sets from UCR for generalizability and transferability. Their experiment showed significant gain in classification accuracy and computational efficiency. In authors have carried out transfer learning for each pair of UCR time-series datasets and shown the dependence of the performance of model on pre-training dataset. Further they have given DTW based solution for selecting the pre-training dataset. In authors have used CNN based transfer learning for ﬂood prediction. They have shown CNN with transfer learning can effectively shorten the training time and mean error difference as compared to CNN without transfer learning. However, few shot learning for ECG data classification using SCNN is not yet explored.. In this work, we demonstrate the application of Siamese networks for few shot classifications of ECG. The SCNN is used to make predictions on the query set using the support set, which consists of examples per class. SCNN learns similarity score between pairs of time series. Since SCNN makes use of pairs of time series to learn similarity score, it is not affected class imbalance , and this is one of the reasons for using SCNN in our work. In particular, we use CNN with various filters and concatenate them to learn feature embedding of each time series. The key contributions of this work are summarised as follows .  We demonstrate that the SCNN can learn effective feature embeddings using one-dimensional filters of various lengths.  We demonstrate that the SCNN can adapt to any way shot learning task using smaller number of training samples from the target task. We observe that few shot classifications using SCNN varies marginally after for ECG classification. The rest of the paper is structured as follows . Section III gives the details of the used, Section IV provides datasets, and experimental details, Section provide details on the results obtained and comparison with baseline methods. Finally, the conclusions and future work are in Section VI. II. RELATED WORK This section presents literature review of the current state of the art for ECG classification techniques and few shot learning for time series data. First subsection II-A presents related work for ECG classification techniques. Following subsection II-B describes few-shot learning for time series data. A. ECG classification techniques Electrocardiogram signals have been used significantly for the diagnosis of heart diseases. Traditional methods for ECG classification used clinicians are usually strenuous, time-consuming, and susceptible to clinical experience variability. Current research trends on deep learning show that models trained on huge amount of data can carry out feature extraction directly from the labelled data and diagnose cardiac arrhythmia better than professional . ECG classification studies started with the application of Genetic Algorithms, and Machine Learning algorithms , that focused on designing methods for ECG preprocessing, feature extraction, feature selection, training and testing. With the availability of high computational hardware, deep learning models gained research focus. Deep learning models provide an advantage of automated feature extraction. Several DL models such as two-dimensional CNNs , Long Short Term Memory , Deep Belief Networks , one-dimensional Convolutional Neural Networks , have been proposed that achieve state of the art results on TSC datasets as well as ECG classification. In authors have used two dimensional CNN and showed that using transfer learning approach that involves pretraining on large database. Then fine-tuning on relatively small database improves the performance of the target task. Authors have used for pretraining and PhysioNet/CinC Challenge data set for finetuning. In authors have used Deep Unidirectional LSTM wavelet sequence and Deep Bidirectional LSTM wavelet sequence to get an accuracy of and . In authors have used discriminative DBNs and achieved an accuracy of . Higher accuracy is seen in , because the training set and test set have been taken from the same database. In authors have taken two seconds and five-second segments of ECG and applied one dimensional CNN that results in the accuracy of and . They have used multiple datasets , MIT-BIH Arrhythmia , Creighton University Ventricular Tachyarrhythmia  for better generalization. However, in general, most of the techniques available in the literature are constrained the availability of large labelled data. Therefore, techniques that require fewer labelled samples for ECG classification need to be explored, and towards that direction, we endeavour to explore FSL techniques in the next subsection. B. FSL techniques for time series data Few shot learning is used to learn from scarce data identifying novel classes from very few labelled examples . The seminal research work on few-shot learning started in the early , . The authors used generative models together with complex iterative inference strategies. Few-shot classification has been widely applied thereafter in various application as object recognition , image classification , and text sentiment classification . In recent survey paper on FSL, authors have analyzed few shot learning from three perspectives, i.e. data, model and algorithm. In authors have used few shot time series classification as meta-learning approach for UCR data sets belonging to various domains. The experiments have shown that few shot time series classifications can classify target domain using only smaller number of training samples from the target task. The applicability of meta-learning approaches is as they are biased towards the fixed number of target classes across tasks. Using few-shot learning, they overcome this to train common agent across domains, with each domain having different number of target classes. This approach of classification outperforms Euclidean distance , Dynamic time wrapping , Bag-of-SFA-Symbols , Residual network . However, our work differs from them as they have done pre-training on various domains , which gives lesser classification accuracy. We are using different ECG datasets for pre-training and fine-tuning that results in better classification accuracy. In they have used Reptile with FCN for time series classification with meta-learning. The experiment on the univariate UCR dataset shows that few-shot learning leads to faster convergence with fewer iterations over the non-metalearning equivalent. In our work, we have demonstrated the application of few-shot learning method for ECG classification that can work with resources in memory, power, and time. We need to store few labelled data instead of large dataset for training, so FSL uses less memory than traditional supervised learning. Since less data means less time and power requirement, so can be used in wearable devices. III. METHODOLOGY This section presents our method of using similarity learning to classify ECG data under the FSL scenario accurately. Figure shows ﬂowchart of the various steps involved. We summarize the major steps taken as follows .  Pre Training .  Validation .  Task Sampling .  Task Adaptation . A. Data Preparation Once the datasets have been split into training, validation, and test sets, denoted Dtr, Dval and Dtest respectively, they have to be preprocessed to learn similarity efficiently. Each set contains number of time series and their labels which can be represented as set where is the number of time series in the set, is time series or set of samples at different time stamps of the form , being the number of timestamps or time series length of particular time series, and is the class label corresponding to the time series. To make the data in the training and validation sets ready to be fed into the Siamese Network, we perform the following steps. Each time series from Dtr and Dval is scaled to the same range and post-padded with zeros to match to the same length of Lmax, which is the length of the longest time series among all the three datasets. From Dtr we create training pairs Ptr and from Dval we create validation pairs Pval using Algorithm . Each pair from Ptr and Pval is of the form , where Dtr or Dval, and ′   if if where is the class label corresponding to time series from Dtr or Dval. It is to be noted that the pairs for training, validation, and final tasks for testing are sampled from disjoint sets of classes. This ensures the generalizability of our model, i.e., the ability to classify new unseen examples on previously unseen datasets. In practice we guarantee this using different datasets for each of the three sets Dtr, Dval and Dtest. B. Siamese Network Pre Training and Validation Once pairs for training and validation are made, the Siamese Network is ready to be trained. Ptr is used to train the network and arrive at the optimum set of weights, while Pval is used to tune hyperparameters and test the model’s generalizability. The network architecture and working can be broadly described as follows. It inputs pair of time series and outputs their similarity score. It consists of two modules .module followed relational module as shown in Figure. Embedding Module . It consists of convolutional neural network . The input is padded time series X. There are three main convolutional blocks. Each convolutional block consists of filter and Rectified Linear Unit as its activation function. It is followed batch normalization operation and dropout layer that act as regularizers, and finally, pooling layer. The first convolutional block consists of convolutional filters of length and pooling layer of size . The second convolutional block consists of filters of length and pooling layer of size . The third and last convolutional block consists of filters of length and pooling layer of size . Various filters of multiple lengths are used in each convolutional layer to extract useful temporal information from time series of varying lengths at different time scales. The pooling layers help in reducing the dimensions of the feature maps produced the filters and summarize the features present in region of the feature maps. Figure shows the overall architecture of the embedding module.  Relational Module: The relational module calculates similarity score between two time series and Xj given their embeddings. The function is taken to be symmetric function so that the similarity score is independent of the order of the inputted time series. The exact equation for the similarity score is as follows . Thus, the similarity score is value between and with higher value representing higher degree of similarity between the two time series. C. Testing the Siamese Network Given the preprocessed test set, we test our Siamese Network first sampling FSL tasks and then making the network adapt to each task to give final predictions. Each task consists of randomly sampling time series from each of the classes, that act as the support set, then randomly sampling time series from each of the classes, that act as the query set. Our objective is to accurately classify the NQ queries given NK samples. To make our Siamese Network adapt to any such way shot task, we do the following step. From the embedding module, the embeddings of the support set , ..., NK are obtained. These embeddings are then averaged class-wise to obtain feature vectors ..., each representing one of the classes. The queries’ embeddings Qj , ..., NQ are also obtained. The final class label for each query is given as . DATASETS AND EXPERIMENTAL DETAILS A. Dataset Description In this paper, we have used the and datasets from the UCR Archive for training purposes, TwoLeadECG and ECGFiveDays datasets from the UCR Archive for validation. We have selected different data sets for training and validation to decrease overfitting and generalization errors. The testing for few shot classification has been carried out on MIT-BIH Arrhythmia Database. . The MIT-BIH dataset has ECG recordings from different subjects recorded at the sampling rate of . Two cardiologists have labeled each beat independently. Further, these annotations are used to create five different beat categories denoted as S, F, and Q. The properties of the different ECG datasets used are shown in Table I. The maximum length of time series in MIT-BIH dataset is . B. Experimental Setup Pretraining and Validation . Pairs are made using the Algorithm . The pretraining then becomes binary classification problem with the objective of classifying pair of time series correctly. Weights are taken so as to minimize the binary cross-entropy of the validation set between the binary class label and the predicted similarity score. The Adam optimizer is used with an initial learning rate of and early stopping with the patience of epochs. The optimum number of filters, filter sizes, and pooling sizes is found out using the Hyperband algorithm to minimize the validation loss.  FSL Task Sampling and Adaptation . For each FSL task, we randomly sample time series from each of the classes, which forms the support set. We also randomly sample queries per class, giving total of queries per task. From the embedding module, we get embeddings for the support set and embeddings for the query set. From the embeddings of the support set, we obtain feature vectors via class-wise averaging of embeddings. For each query, we feed its embedding along with one of the feature vectors into the relational modules to obtain similarity score and repeat times with each of the feature vectors. The final predicted label for the query is taken as the maximum of the similarity scores. The above process is repeated for each of the queries, and the accuracy of the task is measured. The final metrics, such as accuracy, macro precision, macro recall, and macro score, are reported as the mean of the corresponding metrics of such tasks. C. Baselines Considered We consider the following baselines and compare their results with our model.  Dynamic Time Warping . An advantage of DTW is that no preprocessing is required, even for time series of different lengths. The final accuracy is reported as the average of tasks. Tasks are sampled in the same way as for our Siamese Network, as mentioned in Section . For every query, DTW distances are computed between the query and every element in the support set, and the label of the nearest Neighbour is taken as the label of the query.  Euclidean Distance . However, it has been shown to perform inferior to DTW and has the additional condition that the time series have to be of the same length. Here we report the final accuracy as average accuracy of tasks of queries each.  LSTM-Fully Convolutional Network . It entails the augmentation of fully convolutional networks with LSTM submodules for TSC. We train the model for epochs and use an Adam optimizer with an initial learning rate of . The experiment is repeated twenty times, and the average accuracy is reported. V. RESULTS AND DISCUSSION We evaluate results based on the average accuracies of the tasks sampled as mentioned in section . We vary the value of and observe its effect on the final accuracy. Table II shows the accuracy obtained using different models with selected values of while Figure shows the plot of accuracy for the various models as is varied from to . The plots and tables show some interesting results. ED follows nearly monotonically increasing behavior of precision, recall, and score with an increase in K. DTW does not follow such smooth behavior and underperforms in comparison to ED for smaller values of K. However, we see DTW outperforms ED for values closer to and could possibly do even better for values larger than . Unlike ED and DTW, the FCN-LSTM shows extremely irregular behavior as we keep adding samples to train, with large spikes in accuracy at certain places. This could be attributed due to the stochastic nature of the optimization of the neural networks while training, as well as the lack of labeled data, to train on. Most interestingly, in our model, we see huge jump in accuracy from to nearly . From to there is jump around . After there seems to be very less change in accuracy, less than . From till the accuracy does not increase monotonically but plateaus at around . The recall, precision, and score also plateau at around as seen in Table III. A plausible hypothesis for this curve given our model is as follows. single sample of time series, i.e., is not good enough to represent the class it belongs to. As we take the mean of the embedding of more than one time series, the representation of class label becomes more accurate, and the model gives ’better’ similarity score. However, after certain value of the mean of such time series has already yielded good representation of the class, and further inclusion of time series hardly makes difference to accuracy. For all values of our model outperforms other models in accuracy. We do notice that the LSTM-FCN shows promising performance and could potentially outperform the Siamese Network in the presence of more data. Yet, under the fewshot learning scenario, it shows heavy overfitting and cannot adapt quickly to new, unseen examples. VI. CONCLUSIONS AND FUTURE WORK This work demonstrates transfer learning based on few shot classifications on ECG data using Siamese convolutional neural networks that can work satisfactorily without large amount of labelled data. Siamese convolutional neural networks make use of similarity learning that helps to overcome the problem of class imbalance as ECG data are mostly imbalanced with the majority of the beats are normal, and only few beats are abnormal . We have shown that SCNNs are capable of learning feature embeddings using onedimensional filters of different lengths. Our experiments show that FSL using SCNN outperforms ED, DTW, LSTM based methods. It has also been shown that after specific , increasing the value of marginally improves the performance in FSL using SCNN for ECG time-series datasets. In the future, we will compare the performance and overheads with other few-shot learning architectures that have shown promising results in computer vision tasks. This work can be extended converting the original one- dimensional ECG data into the time-frequency spectrograms as the input of models. converting to time-frequency spectrograms , one can take advantage of temporal information embedded in ECG.