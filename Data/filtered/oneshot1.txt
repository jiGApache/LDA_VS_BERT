 The process of learning good features for machine learning applications can be very computationally expensive and may prove difficult in cases where little data is available. prototypical example of this is the one-shot learning setting, in which we must correctly make predictions given only single example of each new class. In this paper, we explore method for learning siamese neural networks which employ unique structure to naturally rank similarity between inputs. Once network has been tuned, we can then capitalize on powerful discriminative features to generalize the predictive power of the network not just to new data, but to entirely new classes from unknown distributions. Using convolutional architecture, we are able to achieve strong results which exceed those of other deep learning models with near state-of-the-art performance on one-shot classification tasks. Humans exhibit strong ability to acquire and recognize new patterns. In particular, we observe that when presented with stimuli, people seem to be able to understand new concepts quickly and then recognize variations on these concepts in future percepts . Machine learning has been successfully used to achieve state-ofthe-art performance in variety of applications such as web search, spam detection, caption generation, and speech and image recognition. However, these algorithms often break down when forced to make predictions about data for which little supervised information is available. We desire to generalize to these unfamiliar categories without necessitating extensive retraining which may be either expensive or impossible due to data or in an online prediction setting, such as web retrieval. One particularly interesting task is classification under the restriction that we may only observe single example of each possible class before making prediction about test instance. This is called one-shot learning and it is the primary focus of our model presented in this work . This should be distinguished from zero-shot learning, in which the model cannot look at any examples from the target classes . One-shot learning can be directly addressed developing domain-specific features or inference procedures which possess highly discriminative properties for the target task. As result, systems which incorporate these methods tend to excel at similar instances but fail to offer robust solutions that may be applied to other types of problems. In this paper, we present novel approach which assumptions on the structure of the inputs while automatically acquiring features which enable the model to generalize successfully from few examples. We build upon the deep learning framework, which uses many layers of non-linearities to capture invariances to transformation in the input space, usually leveraging model with many parameters and then using large amount of data to prevent overfitting . These features are very powerful because we are able to learn them without imposing strong priors, although the cost of the learning algorithm itself may be considerable.  . Approach In general, we learn image representations via supervised metric-based approach with siamese neural networks, then reuse that network’s features for one-shot learning without any retraining. In our experiments, we restrict our attention to character recognition, although the basic approach can be replicated for almost any modality . For this domain, we employ large siamese convolutional neural networks which are capable of learning generic image features useful for making predictions about unknown class distributions even when very few examples from these new distributions are available; are easily trained using standard optimization techniques on pairs sampled from the source data; and provide competitive approach that does not rely upon domain-specific knowledge instead exploiting deep learning techniques. To develop model for one-shot image classification, we aim to first learn neural network that can discriminate between the class-identity of image pairs, which is the standard verification task for image recognition. We hypothesize that networks which do well at at verification should generalize to one-shot classification. The verification model learns to identify input pairs according to the probability that they belong to the same class or different classes. This model can then be used to evaluate new images, exactly one per novel class, in pairwise manner against the test image. The pairing with the highest score according to the verification network is then awarded the highest probability for the one-shot task. If the features learned the verification model are sufficient to confirm or deny the identity of characters from one set of alphabets, then they ought to be sufficient for other alphabets, provided that the model has been exposed to variety of alphabets to encourage variance amongst the learned features.  . Related Work Overall, research into one-shot learning algorithms is fairly immature and has received attention the machine learning community. There are nevertheless few key lines of work which precede this paper. The seminal work towards one-shot learning dates back to the early with work Li Fei-Fei et al. The authors developed variational Bayesian framework for oneshot image classification using the premise that previously learned classes can be leveraged to help forecast future ones when very few examples are available from given class . More recently, Lake et al. approached the problem of one-shot learning from the point of view of cognitive science, addressing one-shot learning for character recognition with method called Hierarchical Bayesian Program Learning . In series of several papers, the authors modeled the process of drawing characters generatively to decompose the image into small pieces . The goal of HBPL is to determine structural explanation for the observed pixels. However, inference under HBPL is difficult since the joint parameter space is very large, leading to an intractable integration problem. Some researchers have considered other modalities or transfer learning approaches. Lake et al. have some very recent work which uses generative Hierarchical Hidden Markov model for speech primitives combined with Bayesian inference procedure to recognize new words unknown speakers . Maas and Kemp have some of the only published work using Bayesian networks to predict attributes for Ellis Island passenger data . Wu and Dennis address one-shot learning in the context of path planning algorithms for robotic actuation . Lim focuses on how to “borrow” examples from other classes in the training set adapting measure of how much each category should be weighted each training exemplar in the loss function . This idea can be useful for datasets where very few examples exist for some classes, providing ﬂexible and continuous means of incorporating inter-class information into the model.  . Deep Siamese Networks for Image Verification Siamese nets were first introduced in the early Bromley and LeCun to solve signature verification as an image matching problem . siamese neural network consists of twin networks which accept distinct inputs but are joined an energy function at the top. This function computes some metric between the highestlevel feature representation on each side . The parameters between the twin networks are tied. Weight tying guarantees that two extremely similar images could not possibly be mapped their respective networks to very different locations in feature space because each network computes the same function. Also, the network is symmetric, so that whenever we present two distinct images to the twin networks, the top conjoining layer will compute the same metric as if we were to we present the same two images but to the opposite twins. In LeCun et al., the authors used contrastive energy function which contained dual terms to decrease the energy of like pairs and increase the energy of unlike pairs . However, in this paper we use the weighted distance between the twin feature vectors and combined with sigmoid activation, which maps onto the interval . Thus cross-entropy objective is natural choice for training the network. Note that in LeCun et al., they directly learned the similarity metric, which was implictly defined the energy loss, whereas we fix the metric as specified above, following the approach in Facebook’s DeepFace paper . Our best-performing models use multiple convolutional layers before the fully-connected layers and top-level energy function. Convolutional neural networks have achieved exceptional results in many large-scale computer vision applications, particularly in image recognition tasks . Several factors make convolutional networks especially appealing. Local connectivity can greatly reduce the number of parameters in the model, which inherently provides some form of built-in regularization, although convolutional layers are computationally more expensive than standard nonlinearities. Also, the convolution operation used in these networks has direct filtering interpretation, where each feature map is convolved against input features to identify patterns as groupings of pixels. Thus, the outputs of each convolutional layer correspond to important spatial features in the original input space and offer some robustness to simple transforms. Finally, very fast CUDA libraries are now available in order to build large convolutional networks without an unacceptable amount of training time . We now detail both the structure of the siamese nets and the specifics of the learning algorithm used in our experiments.  . Model Our standard model is siamese convolutional neural network with layers each with Nl units, where represents the hidden vector in layer for the first twin, and denotes the same for the second twin. We use exclusively rectified linear units in the first layers and sigmoidal units in the remaining layers. The model consists of sequence of convolutional layers, each of which uses single channel with filters of varying size and fixed stride of . The number of convolutional filters is specified as multiple of to optimize performance. The network applies ReLU activation function to the output feature maps, optionally followed maxpooling with filter size and stride of . Thus the kth filter map in each layer takes the following form: max-pool ⋆ max-pool ⋆ where is the tensor representing the feature maps for layer and we have taken ⋆ to be the valid convolutional operation corresponding to returning only those output units which were the result of complete overlap between each convolutional filter and the input feature maps. The units in the final convolutional layer are ﬂattened into single vector. This convolutional layer is followed fully-connected layer, and then one more layer computing the induced distance metric between each siamese twin, which is given to single sigmoidal output unit. More precisely, the prediction vector is given as where is the sigmoidal activation function. This final layer induces metric on the learned feature space of the th hidden layer and scores the similarity between the two feature vectors. The are additional parameters that are learned the model during training, weighting the importance of the component-wise distance. This defines final Lth fully-connected layer for the network which joins the two siamese twins. We depict one example above , which shows the largest version of our model that we considered. This network also gave the best result for any network on the verification task.  . Learning Loss function. Let represent the minibatch size, where indexes the ith minibatch. Now let , be length-M vector which contains the labels for the minibatch, where we assume , whenever and are from the same character class and , otherwise. We impose regularized cross-entropy objective on our binary classifier of the following form . This objective is combined with standard backpropagation algorithm, where the gradient is additive across the twin networks due to the tied weights. We fix minibatch size of with learning rate momentum and regularization weights defined layer-wise, so that our update rule at epoch is as follows . Weight initialization. We initialized all network weights in the convolutional layers from normal distribution with zero-mean and standard deviation of . Biases were also initialized from normal distribution, but with mean and standard deviation . In the fully-connected layers, the biases were initialized in the same way as the convolutional layers, but the weights were drawn from much wider normal distribution with zero-mean and standard deviation . Learning schedule. Although we allowed for different learning rate for each layer, learning rates were decayed uniformly across the network percent per epoch, so that . We found that annealing the learning rate, the network was able to converge to local minima more easily without getting stuck in the error surface. We fixed momentum to start at in every layer, increasing linearly each epoch until reaching the value the individual momentum term for the jth layer. We trained each network for maximum of epochs, but monitored one-shot validation error on set of oneshot learning tasks generated randomly from the alphabets and drawers in the validation set. When the validation error did not decrease for epochs, we stopped and used the parameters of the model at the best epoch according to the one-shot validation error. If the validation error continued to decrease for the entire learning schedule, we saved the final state of the model generated this procedure. We used the beta version of Whetlab, Bayesian optimization framework, to perform hyperparameter selection. For learning schedule and regularization hyperparameters, we set the layerwise learning rate , layer-wise momentum , and layer-wise regularization penalty . For network hyperparameters, we let the size of convolutional filters vary from to while the number of convolutional filters in each layer varied from to using multiples of . Fully-connected layers ranged from to units, also in multiples of . We set the optimizer to maximize one-shot validation set accuracy. The score assigned to single Whetlab iteration was the highest value of this metric found during any epoch. Affine distortions. In addition, we augmented the training set with small affine distortions . For each image pair we generated pair of affine transformations to yield , , where are determined stochastically multidimensional uniform distribution. So for an arbitrary transform we have , with , , , and . Each of these components of the transformation is included with probability .  . Experiments We trained our model on subset of the Omniglot data set, which we first describe. We then provide details with respect to verification and one-shot performance.  . The Omniglot Dataset The Omniglot data set was collected Brenden Lake and his collaborators at MIT via Amazon’s Mechanical Turk to produce standard benchmark for learning from few examples in the handwritten character recognition domain Omniglot contains examples from alphabets ranging from well-established international languages like Latin and Korean to lesser known local dialects. It also includes some fictitious character sets such as Aurek-Besh and Klingon . The number of letters in each alphabet varies considerably from about to upwards of characters. All characters across these alphabets are produced single time each of drawers Lake split the data into alphabet background set and alphabet evaluation set. We preserve these two terms in order to distinguish from the normal training, validation, and test sets that can be generated from the background set in order to tune models for verification. The background set is used for developing model learning hyperparameters and feature mappings. Conversely, the evaluation set is used only to measure the one-shot classification performance.  . Verification To train our verification network, we put together three different data set sizes with and training examples sampling random same and different pairs. We set aside sixty percent of the total data for training . We fixed uniform number of training examples per alphabet so that each alphabet receives equal representation during optimization, although this is not guaranteed to the individual character classes within each alphabet. adding affine distortions, we also produced an additional copy of the data set corresponding to the augmented version of each of these sizes. We added eight transforms for each training example, so the corresponding data sets have and effective examples. To monitor performance during training, we used two strategies. First, we created validation set for verification with example pairs taken from alphabets and additional drawers. We reserved the last alphabets and drawers for testing, where we constrained these to be the same ones used in Lake et al. . Our other strategy leveraged the same alphabets and drawers to generate set of one-shot recognition trials for the validation set which mimic the target task on the evaluation set. In practice, this second method of determining when to stop was at least as effective as the validation error for the verification task so we used it as our termination criterion. In the table below , we list the final verification results for each of the six possible training sets, where the listed test accuracy is reported at the best validation checkpoint and threshold. We report results across six different training runs, varying the training set size and toggling distortions. In Figure we have extracted the first filters from both of our top two performing networks on the verification task, which were trained on the and data sets with affine distortions and the architecture shown in Figure . While there is some co-adaptation between filters, it is easy to see that some of the filters have assumed different roles with respect to the original input space.  . One-shot Learning Once we have optimized siamese network to master the verification task, we are ready to demonstrate the discriminative potential of our learned features at one-shot learning. Suppose we are given test image some column vector which we wish to classify into one of categories. We are also given some other images set of column vectors representing examples of each of those categories. We can now query the network using as our input for range of . . . , Then predict the class corresponding to the maximum similarity. C∗ argmaxcp To empirically evaluate one-shot learning performance, Lake developed within-alphabet classification task in which an alphabet is first chosen from among those reserved for the evaluation set, along with twenty characters taken uniformly at random. Two of the twenty drawers are also selected from among the pool of evaluation drawers. These two drawers then produce sample of the twenty characters. Each one of the characters produced the first drawer are denoted as test images and individually compared against all twenty characters from the second drawer, with the goal of predicting the class corresponding to the test image from among all of the second drawer’s characters. An individual example of one-shot learning trial is depicted in Figure . This process is repeated twice for all alphabets, so that there are one-shot learning trials for each of the ten evaluation alphabets. This constitutes total of one-shot learning trials, from which the classification accuracy is calculated. The one-shot results are given in Table . We borrow the baseline results from for comparison to our method. We also include results from nonconvolutional siamese network with two fully-connected layers. At percent our convolutional method is stronger than any model except HBPL itself. which is only slightly behind human error rates. While HBPL exhibits stronger results overall, our top-performing convolutional network did not include any extra prior knowledge about characters or strokes such as generative information about the drawing process. This is the primary advantage of our model.  . MNIST One-shot Trial The Omniglot data set contains small handful of samples for every possible class of letter; for this reason, the original authors refer to it as sort of “MNIST transpose”, where the number of classes far exceeds the number of training instances . We thought it would be interesting to monitor how well model trained on Omniglot can generalize to MNIST, where we treat the digits in MNIST as an alphabet and then evaluate oneshot classification task. We followed similar procedure to Omniglot, generating one-shot trials on the MNIST test set, but excluding any fine tuning on the training set. All images were upsampled to then given to reduced version of our model trained on images from Omniglot which were downsampled factor of . We also evaluated the nearest-neighbor baseline on this task. Table shows the results from this experiment. The nearest neighbor baseline provides similar performance to Omniglot, while the performance of the convolutional network drops more significant amount. However, we are still able to achieve reasonable generalization from the features learned on Ominglot without training at all on MNIST.  . Conclusions We have presented strategy for performing one-shot classification first learning deep convolutional siamese neural networks for verification. We outlined new results comparing the performance of our networks to an existing state-of-the-art classifier developed for the Omniglot data set. Our networks outperform all available baselines significant margin and come close to the best numbers achieved the previous authors. We have argued that the strong performance of these networks on this task indicate not only that human-level accuracy is possible with our metric learning approach, but that this approach should extend to one-shot learning tasks in other domains, especially for image classification. In this paper, we only considered training for the verification task processing image pairs and their distortions using global affine transform. We have been experimenting with an extended algorithm that exploits the data about the individual stroke trajectories to produce final computed distortions . imposing local affine transformations on the strokes and overlaying them into composite image, we are hopeful that we can learn features which are better adapted to the variations that are commonly seen in new examples.