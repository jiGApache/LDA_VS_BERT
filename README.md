# Topic modeling: BERT vs LDA

## Описание проекта

Целью данного проекта является сравнение двух подходов для решения задачи тематического моделирования научных статей: BERT и LDA. 
Сравнение моделей будет происходить путем сравнения двух метрик каждой модели:
- **Coherence Score** - метрики, которая оценивает, насколько связными являются слова в каждом топике. Более высокий показатель свидетельствует о более связных и интерпретируемых топиках.
- **Jaccard Distance** - метрика, которая оценивает, насколько хорошо топики разделены в корпусе документов.

### LDA
Для реализации модели LDA используется готовая модель из библиотеки ```gensim```, которая помимо этого предоставляет различные  инструменты для создания корпусов текстовых документов и  препроцессинга текстов.

### BERT
Для реализации тематического моделирования с помощью модели BERT исопльзуется готовая библиотека BERTopic, которая в своей основе имеет ряд ключевых компонентов:
- предобученная модель [sentence-transformer](https://www.sbert.net/) для вычисления эмбеддингов предложений текста
- алгоритм UMAP для уменьшения размерности полученных эмбеддингов предложений
- модель HDBSCAN для кластеризации полученных эмбеддингов
- Выделение топиков из каждого полученного кластера при помощи техники c-TF-IDF

### Подбор гиперпараметров моделей
Для получения наилучших результатов была выбрана библиотека Python ```Optuna``` для целей оптимизации. Эта библиотека реализует методы байесовской оптимизации, чтобы итеративно предлагать эффективные гиперпараметры, максимизирующие заданные метрики.


## Используемые данные
### Описание
В качестве исходных данных были использованы 10 научных [статей](#источники) из смежных областей. Примерное распределение тем в каждой статье можно увидеть в следующей таблице:
№ Статьи | Few-Shot | Time Series | Siamese Network | Medicine | Convolutioinal Networks 
--- | :---: | :---: | :---: | :---: | :---:
1  | + | | + | | +
2  | | + | | + | +
3  | | | + | | +
4  | + | | | | +
5  | + | + | | + | +
6  | | | + | + | +
7  | + | + | + | + | + 
8  | | | | + | +
9  | | | | + | +
10  | + | | + | | +

### Предобработка данных
В качестве предварительной обработки исходных текстов были проведены следующие действия:
- Удаление частей статей, находящихся перед заголовком "Abstract" и после "References"
- Удаление подписей к рисункам и таблицам
- Восстановление переносов слов и разрывов предложений
- Удаление содержимого всех скобок, а также всех математических выражений (формул, отдельных переменных и операторов, чисел и т.д.)
- Удаление повторяющихся пробелов, коротких предложений и знаков препинания (за исключением знака конца предложения)
- Удаление "стоп" слов и стемминг

После этого на вход модели BERTopic подавался список предложений из всех текстов, а LDA - список отдельно токенизированных текстов.

## Результаты

После обучения моделей для каждой было получено единственный наиболее эффективный набор гиперпараметров, решающих задачу максимизации заданных метрик. Далее представлены результаты работы моделей на основе полученных гиперпараметров.

### LDA

Ниже представлены топики, полученные моделью LDA на основе эффективных гиперпараметров:
```
Topics:
[(0, '0.034*"beat" + 0.024*"classifi" + 0.023*"ecg" + 0.020*"arrhythmia"'),
 (1, '0.037*"test" + 0.029*"train" + 0.026*"updat" + 0.026*"set"'),
 (2, '0.071*"learn" + 0.034*"data" + 0.024*"train" + 0.024*"few-shot"'),
 (3, '0.024*"embed" + 0.024*"verif" + 0.022*"comput" + 0.018*"model"'),
 (4, '0.046*"learn" + 0.033*"meta-learn" + 0.020*"task" + 0.018*"transfer"'),
 (5, '0.054*"class" + 0.042*"dataset" + 0.030*"use" + 0.029*"imag"'),
 (6, '0.027*"detect" + 0.027*"work" + 0.024*"propos" + 0.024*"perform"'),
 (7, '0.081*"time" + 0.062*"seri" + 0.023*"number" + 0.014*"length"'),
 (8, '0.043*"accuraci" + 0.028*"result" + 0.023*"tabl" + 0.021*"model"'),
 (9, '0.072*"ecg" + 0.047*"signal" + 0.032*"featur" + 0.021*"layer"'),
 (10, '0.043*"layer" + 0.024*"task" + 0.017*"convolut" + 0.017*"loss"'),
 (11, '0.068*"network" + 0.030*"classif" + 0.027*"convolut" + 0.025*"neural"')]
Coherence score: 0.6761214132852379
Jaccard distance: f0.9027777777777778
```
Среди полученных топиков можно рассмотреть, что выделяются темы, предположительно связанные с:
  - данными ЭКГ и их классификацией
  - обучением сети с подходом Few-Shot
  - трансферным обучением
  - временными рядами
  - сверточными сетями

Не удалось обнаружить топик, который был бы связан с сиамскими сетями.

### BERTopic

Ниже представлены топики, полученные моделью BERTopic на основе эффективных гиперпараметров:

```
   Topic  Count                                Name
0     -1    712              -1_use_model_train_ecg
1      0    102  0_network_siames_architectur_fulli
2      1    101     1_fewshot_learn_oneshot_retriev
3      2     97          2_sampl_metaset_class_test
4      3     95        3_layer_filter_convolut_pool
5      4     78    4_accuraci_section_detail_averag
6      5     50      5_dnn_transfer_largescal_train
7      6     48         6_neural_arrhythmia_ecg_cnn
Coherence score: 0.6494877739519195
Jaccard distance: f0.8571428571428571
```

На основе полученных данных можно предположить, что:
- выделен топик, характеризующий статьи про сиамские сети
- обозначен топик про подход Few-Shot
- выделены топики, связанные со сверточными сетями и их применении в обработке данных ЭКГ
- выделен топик, связанный с глубоким и трансферным обучением

Не удалось обнаружить топик, который был бы связан с временными рядами.
  
### Сравнение результатов

Ниже можно увидеть отображение максимизированных метрик на координатной плоскости.

![Alt text](https://github.com/jiGApache/LDA_VS_BERT/raw/main/images/1.png)

Как можно увидеть, модель LDA немного лучше справляется как с формированием более связанных топиков, так и разделением этих топиков, чем модель BERTopic.

## Выводы

Можно сказать, что оба подхода в определенной степени справляются с решением задачи тематического моделирования научных статей.

Сравнение полученных метрик **Coherence Score** и **Jaccard Distance** каждой модели, показывает, что модель LDA проявила себя лучше при решении вышеупомянутой задачи. Хотя стоит отметить, что разница в показателях невелика и может быть объяснена невозможностью обучения моделей в абсолютно равных условиях.

Это косвенно подтверждается при визуальном анализе результатов: обе модели смогли выделить как все основные топики, присущие статьям, так и выделить выделены топики, которые не удалось обозначить при предварительной оценке статей (например применение подхода глубокого или трансферного обучения).

## Источники
1. Few-Shot Learning Through an Information Retrieval Lens - https://arxiv.org/abs/1707.02610
2. ECG Heartbeat Classification: A Deep Transferable Representation - https://arxiv.org/pdf/1805.00794.pdf
3. Fully Convolutional Siamese Networks for Change Detection - https://arxiv.org/abs/1810.08462
4. Meta-Transfer Learning for Few-Shot Learning - https://arxiv.org/abs/1812.02391
5. Meta-Learning for Few-Shot Time Series Classification - https://arxiv.org/abs/1909.07155
6. EDITH : ECG biometrics aided by Deep learning for reliable Individual auTHentication - https://arxiv.org/abs/2102.08026
7. Similarity Learning based Few Shot Learning for ECG Time Series Classification - https://ieeexplore.ieee.org/document/9647357
8. Automated Detection of Arrhythmias Using Different Intervals of Tachycardia ECG Segments with Convolutional Neural Network - https://www.researchgate.net/publication/315821873_Automated_Detection_of_Arrhythmias_Using_Different_Intervals_of_Tachycardia_ECG_Segments_with_Convolutional_Neural_Network
9. ECG Arrhythmia Classification Using STFT-Based Spectrogram and Convolutional Neural Network - https://ieeexplore.ieee.org/document/8759878
10. Siamese Neural Networks for One-shot Image Recognition - https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf
